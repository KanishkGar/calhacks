{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7570b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For colab install these libraries in this order:\n",
    "# !pip install milvus, pymilvus, langchain, torch, transformers, python-dotenv\n",
    "\n",
    "# Import common libraries.\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de06f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = './content/books.csv'  # Download it from https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks and save it in the folder that holds your script.\n",
    "COLLECTION_NAME = 'title_db'  # Collection name\n",
    "DIMENSION = 1536  # Embeddings size\n",
    "COUNT = 100  # How many titles to embed and insert.\n",
    "MILVUS_HOST = 'localhost'  # Milvus server URI\n",
    "MILVUS_PORT = '19530'\n",
    "OPENAI_ENGINE = 'text-embedding-ada-002'  # Which engine to use\n",
    "openai.api_key = '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'  # Use your own Open AI API Key here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67e382",
   "metadata": {},
   "source": [
    "## Start up a local Milvus server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb844837",
   "metadata": {},
   "source": [
    "Code in this notebook uses [Milvus client](https://milvus.io/docs/using_milvusclient.md) with [Milvus lite](https://milvus.io/docs/milvus_lite.md), which runs a local server.  â›”ï¸ Milvus lite is only meant for demos and local testing.\n",
    "- pip install milvus pymilvus\n",
    "\n",
    "ðŸ’¡ **For production purposes**, use a local Milvus docker, Milvus clusters, or fully-managed Milvus on Zilliz Cloud.\n",
    "- [Local Milvus docker](https://milvus.io/docs/install_standalone-docker.md) requires local docker installed and running.\n",
    "- [Milvus clusters](https://milvus.io/docs/install_cluster-milvusoperator.md) requires a K8s cluster up and running.\n",
    "- [Ziliz Cloud free trial](https://cloud.zilliz.com/login) choose a \"free\" option when you provision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0806d2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from milvus import default_server\n",
    "from pymilvus import (\n",
    "    connections, utility, \n",
    "    MilvusClient, \n",
    "    FieldSchema, DataType, CollectionSchema, Collection\n",
    ")\n",
    "\n",
    "connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "\n",
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    utility.drop_collection(COLLECTION_NAME)\n",
    "\n",
    "fields = [\n",
    "    # id format: class:lecture:start_second:end_second - eg. cs162:1:543:600\n",
    "    FieldSchema(name='id', dtype=DataType.VARCHAR, description='Ids', is_primary=True, auto_id=False, max_length=100),\n",
    "    FieldSchema(name='caption', dtype=DataType.VARCHAR, description='Title texts', max_length=2000),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, description='Embedding vectors', dim=DIMENSION)\n",
    "]\n",
    "schema = CollectionSchema(fields=fields, description='Title collection')\n",
    "collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
    "\n",
    "index_params = {\n",
    "    'index_type': 'IVF_FLAT',\n",
    "    'metric_type': 'L2',\n",
    "    'params': {'nlist': 1024}\n",
    "}\n",
    "collection.create_index(field_name=\"embedding\", index_params=index_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "580d52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_seconds(time: str) -> int:\n",
    "    # convert times of the format m:ss, mm:ss, h:mm:ss, and hh:mm:ss to seconds\n",
    "    time_list: list = time.split(':')\n",
    "    time_list.reverse()\n",
    "\n",
    "    seconds: int = sum(\n",
    "        int(time_list[i]) * (60**i) for i in range(len(time_list))\n",
    "    )\n",
    "    return seconds\n",
    "\n",
    "def merge_into_minutes(start_end_texts: list) -> list:\n",
    "    # makes each range at least a minute long\n",
    "    merged_start_end_texts: list = [start_end_texts[0]]\n",
    "    MIN_SECONDS_PER_BLOB: int = 60\n",
    "\n",
    "    for start_time, end_time, text in start_end_texts[1:]:\n",
    "        if start_time - merged_start_end_texts[-1][0] < MIN_SECONDS_PER_BLOB:\n",
    "            merged_start_end_texts[-1][1] = end_time\n",
    "            merged_start_end_texts[-1][2] += f' {text}'\n",
    "        else:\n",
    "            merged_start_end_texts.append([start_time, end_time, text])\n",
    "    \n",
    "    return merged_start_end_texts\n",
    "        \n",
    "\n",
    "def process_text_file(text_file: str, total_time: str) -> list:\n",
    "    with open(text_file, 'r') as f:\n",
    "        text_lines: list = f.read().splitlines()\n",
    "\n",
    "    start_end_texts: list = []\n",
    "\n",
    "    for i in range(0, len(text_lines) - 2, 2):\n",
    "        start_time: int = convert_to_seconds(text_lines[i])\n",
    "        end_time: int = convert_to_seconds(text_lines[i + 2])\n",
    "        text: str = text_lines[i + 1]\n",
    "\n",
    "        start_end_texts.append([start_time, end_time, text])\n",
    "    \n",
    "    start_end_texts.append([convert_to_seconds(text_lines[-2]), convert_to_seconds(total_time), text_lines[-1]])\n",
    "    merged_texts: list = merge_into_minutes(start_end_texts)\n",
    "\n",
    "    return merged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20029d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current processing cs162 lecture 1\n",
      "Loading dictionary from pickle file...\n",
      "current processing cs162 lecture 2\n",
      "Loading dictionary from pickle file...\n",
      "current processing cs162 lecture 3\n",
      "Loading dictionary from pickle file...\n",
      "current processing cs162 lecture 4\n",
      "Loading dictionary from pickle file...\n",
      "current processing cs162 lecture 5\n",
      "Loading dictionary from pickle file...\n",
      "current processing cs162 lecture 6\n",
      "Loading dictionary from pickle file...\n",
      "current processing cs162 lecture 7\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 8\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 9\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 10\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 11\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 12\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 13\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 14\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 15\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 16\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 17\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 18\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 19\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 20\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 21\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 22\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 23\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 24\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 25\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n",
      "current processing cs162 lecture 26\n",
      "Computing dictionary...\n",
      "Saving dictionary to pickle file...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def embed(text):\n",
    "    return openai.Embedding.create(\n",
    "        input=text, \n",
    "        engine=OPENAI_ENGINE)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def process_class_lecture(class_name: str, lecture: str, length: str):\n",
    "    print(f\"current processing {class_name} lecture {lecture}\")\n",
    "    video_text = process_text_file(f'./{class_name}/{lecture}.txt', length)\n",
    "    def compute_dictionary():\n",
    "        start_stop_dic = {}\n",
    "\n",
    "        for start, stop, text in video_text:  # Load COUNT amount of random values from dataset\n",
    "            # ins=[[idx], [(text[:198] + '..') if len(text) > 200 else text], [embed(text)]]  # Insert the title id, the title text, and the title embedding vector\n",
    "            ins = [\n",
    "                # id format: class:lecture:start_second:end_second - eg. cs162:1:543:600\n",
    "                [f\"{class_name}:{lecture}:{start}:{stop}\"],\n",
    "                [f'{text[:1998]}..' if len(text) > 2000 else text],\n",
    "                [embed(text)],\n",
    "            ]\n",
    "            start_stop_dic[start] = ins\n",
    "\n",
    "        return start_stop_dic\n",
    "\n",
    "    def save_dict_to_pickle(my_dict, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(my_dict, f)\n",
    "\n",
    "    def load_dict_from_pickle(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    filename = f\"./{class_name}_pickle/{lecture}.pickle\"\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        print(\"Loading dictionary from pickle file...\")\n",
    "        start_stop_dic = load_dict_from_pickle(filename)\n",
    "    else:\n",
    "        print(\"Computing dictionary...\")\n",
    "        start_stop_dic = compute_dictionary()\n",
    "        print(\"Saving dictionary to pickle file...\")\n",
    "        save_dict_to_pickle(start_stop_dic, filename)\n",
    "    \n",
    "    return start_stop_dic\n",
    "\n",
    "def process_162():\n",
    "    cs_162_lectures = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\"]\n",
    "    cs_162_lecture_lengths = [\"1:23:02\", \"1:22:19\", \"1:27:53\", \"1:28:16\", \"1:26:42\", \"1:30:29\", \"1:27:34\", \"1:28:31\", \"1:29:08\", \"1:28:06\", \"1:27:21\", \"1:26:21\", \"1:28:41\", \"1:24:33\", \"1:27:15\", \"1:29:40\", \"1:24:31\", \"1:27:45\", \"1:28:51\", \"1:29:04\", \"1:26:51\", \"1:27:13\", \"1:27:06\", \"1:28:50\", \"1:30:19\", \"1:34:52\"]\n",
    "    for lecture, length in zip(cs_162_lectures, cs_162_lecture_lengths):\n",
    "        start_stop_dic = process_class_lecture(\"cs162\", lecture, length)\n",
    "        for start, ins in start_stop_dic.items():\n",
    "            collection.insert(ins)\n",
    "\n",
    "process_162()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a576a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search term: how to implement locks\n",
      "['cs162:3:4196:4257', 0.3414938151836395, \"it are put to sleep and when that thread that has a lock finally releases it then one and only one of those threads is allowed to acquire it so this mutual exclusion given by locks okay namely only one thread can acquire at a time is going to allow us to start building correct code even with a lot of parallelism and concurrency in there okay and don't worry about how to implement this we will talk about that in great detail later but how would we use that in this example well uh the two threads would acquire a lock on the whole data structure or on the root of it okay insert three and then release it or maybe thread b acquires the lock inserts four and releases it um there's a an elegance to how to distribute your locks that you're gonna get to start thinking about like you could have a single lock at the root and if you grab a lock then you know that if a grabs the lock then it knows that\"]\n",
      "['cs162:7:2448:2509', 0.3552582561969757, \"to to start thinking about this remember we've been talking about locks right a lock is basically preventing somebody from doing something okay and you lock before entering the critical section you unlock after leaving and uh you wait if locked okay and remember the most important idea behind synchronization is that all synchronization problems are solved by waiting in one form or another the trick is to wait as little as possible or if you're forced to wait for a longer period of time don't steal cycles don't waste cycles basically let somebody else run okay but it's all about waiting uh cleverly okay and so for example we could fix this milk problem by putting a key on the refrigerator you lock it you take the key and you go buy milk okay now i don't know about you but i suspect this fixes too much right because if your roommate only wants orange juice um then that's a problem okay so uh of course we don't know how to\"]\n",
      "['cs162:6:4709:4769', 0.3646085858345032, \"critical section you unlock uh when you're done and you wait if the thing's already locked uh you wait for it to be unlocked and so the key idea here is that all synchronization in order to make something correct it always involves waiting so rather than running right away you wait so that the atomic sections don't get interleaved okay so waiting is actually a good thing here as long as you don't do it excessively okay and so typically as we mentioned several extras ago locks need to be allocated so it might be something like uh you know structure lock mylock and then you knit it or maybe p thread mutex mylock and you initialize it all the different systems have different ways of initializing the lock and then you typically have a choir which grabs a lock and release and they often take a pointer to the particular lock okay so how do we fix the banking problem well we put locks around our atomic section so we acquire the lock\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collection.load()\n",
    "\n",
    "def search(text):\n",
    "    # Search parameters for the index\n",
    "    search_params={\n",
    "        \"metric_type\": \"L2\"\n",
    "    }\n",
    "\n",
    "    results=collection.search(\n",
    "        data=[embed(text)],  # Embeded search value\n",
    "        anns_field=\"embedding\",  # Search across embeddings\n",
    "        param=search_params,\n",
    "        limit=5,  # Limit to five results per search\n",
    "        output_fields=['caption']  # Include caption field in result\n",
    "    )\n",
    "\n",
    "    ret=[]\n",
    "    for hit in results[0]:\n",
    "        row = [hit.id, hit.score, hit.entity.get('caption')]\n",
    "        ret.append(row)\n",
    "    return ret\n",
    "\n",
    "search_terms=['how to implement locks']\n",
    "\n",
    "for x in search_terms:\n",
    "    print('Search term:', x)\n",
    "    for result in search(x):\n",
    "        print(result)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
